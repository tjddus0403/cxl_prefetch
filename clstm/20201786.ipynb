{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sykim/miniconda3/envs/prefetch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/tmp/ipykernel_130219/533703381.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Namespace(\n",
    "    perc_train = 0.5,\n",
    "    perc_val = 0.2,\n",
    "    perc_test = 0.3,\n",
    "    perc_vocab = 1,\n",
    "    dataset = \"../sim/deep_learning_data/pr_1MB.cstate\",\n",
    "    dataset_csv = \"datasets/pr_1MB.csv\",\n",
    "    # dataset_csv = \"bert_pf_before.csv\",\n",
    "    seed = 1337,\n",
    "    lr = 5e-4,\n",
    "    batch_size = 64,\n",
    "    num_epoch = 200,\n",
    "    embedding_size = 64,\n",
    "    encoding_size = 32,\n",
    "    cut_off = 1,\n",
    "    max_len = 128,\n",
    "    cuda = True,\n",
    "    device = 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed_everywhere(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "# 재현성을 위해 시드 설정\n",
    "set_seed_everywhere(args.seed, args.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recreate Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = list()\n",
    "output_list = list()\n",
    "with open(args.dataset, 'r') as dataset:\n",
    "    line = dataset.readline().split()\n",
    "    while line:\n",
    "        strline = [str(dstr) for dstr in line]\n",
    "        input_list.append(\" \".join(strline[:-1]))\n",
    "        output_list.append(strline[-1])\n",
    "        line = dataset.readline().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31854774143 31854774142 31854774141 3185477414...</td>\n",
       "      <td>42318532544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42318532591 42318532590 42318532589 4231853258...</td>\n",
       "      <td>48286355124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48286355135 48286355134 48286355133 4828635513...</td>\n",
       "      <td>23732197760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23732197823 23732197822 23732197821 2373219782...</td>\n",
       "      <td>7432544128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7432544179 7432544180 7432544178 7432544177 74...</td>\n",
       "      <td>65249514352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036778</th>\n",
       "      <td>23732197811 23732197809 23732197806 2373219780...</td>\n",
       "      <td>23732197819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036779</th>\n",
       "      <td>23732197819 23732197811 23732197809 2373219780...</td>\n",
       "      <td>23732197821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036780</th>\n",
       "      <td>23732197821 23732197819 23732197811 2373219780...</td>\n",
       "      <td>7432544128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036781</th>\n",
       "      <td>7432544130 7432544129 7432544128 23732197821 2...</td>\n",
       "      <td>7432544135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4036782</th>\n",
       "      <td>7432544135 7432544130 7432544129 7432544128 23...</td>\n",
       "      <td>7432544139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4036783 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        pa        label\n",
       "0        31854774143 31854774142 31854774141 3185477414...  42318532544\n",
       "1        42318532591 42318532590 42318532589 4231853258...  48286355124\n",
       "2        48286355135 48286355134 48286355133 4828635513...  23732197760\n",
       "3        23732197823 23732197822 23732197821 2373219782...   7432544128\n",
       "4        7432544179 7432544180 7432544178 7432544177 74...  65249514352\n",
       "...                                                    ...          ...\n",
       "4036778  23732197811 23732197809 23732197806 2373219780...  23732197819\n",
       "4036779  23732197819 23732197811 23732197809 2373219780...  23732197821\n",
       "4036780  23732197821 23732197819 23732197811 2373219780...   7432544128\n",
       "4036781  7432544130 7432544129 7432544128 23732197821 2...   7432544135\n",
       "4036782  7432544135 7432544130 7432544129 7432544128 23...   7432544139\n",
       "\n",
       "[4036783 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data = pd.DataFrame(input_list, columns=['pa'])\n",
    "final_data['label'] = output_list\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv(args.dataset_csv, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv(args.dataset_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31854774143 31854774142 31854774141 3185477414...</td>\n",
       "      <td>42318532544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42318532591 42318532590 42318532589 4231853258...</td>\n",
       "      <td>48286355124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48286355135 48286355134 48286355133 4828635513...</td>\n",
       "      <td>23732197760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23732197823 23732197822 23732197821 2373219782...</td>\n",
       "      <td>7432544128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7432544179 7432544180 7432544178 7432544177 74...</td>\n",
       "      <td>65249514352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>23732197807 60916115883 23732197790 4231853258...</td>\n",
       "      <td>23732197809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>23732197809 23732197807 60916115883 2373219779...</td>\n",
       "      <td>23732197811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>23732197813 23732197811 23732197809 2373219780...</td>\n",
       "      <td>7432544134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>7432544154 7432544134 23732197813 23732197811 ...</td>\n",
       "      <td>7432544178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>7432544178 7432544154 7432544134 23732197813 2...</td>\n",
       "      <td>58858693333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     pa        label\n",
       "0     31854774143 31854774142 31854774141 3185477414...  42318532544\n",
       "1     42318532591 42318532590 42318532589 4231853258...  48286355124\n",
       "2     48286355135 48286355134 48286355133 4828635513...  23732197760\n",
       "3     23732197823 23732197822 23732197821 2373219782...   7432544128\n",
       "4     7432544179 7432544180 7432544178 7432544177 74...  65249514352\n",
       "...                                                 ...          ...\n",
       "9994  23732197807 60916115883 23732197790 4231853258...  23732197809\n",
       "9995  23732197809 23732197807 60916115883 2373219779...  23732197811\n",
       "9996  23732197813 23732197811 23732197809 2373219780...   7432544134\n",
       "9997  7432544154 7432544134 23732197813 23732197811 ...   7432544178\n",
       "9998  7432544178 7432544154 7432544134 23732197813 2...  58858693333\n",
       "\n",
       "[9999 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['pa'] = dataset_df['pa'].shift(periods=2, axis=0)\n",
    "dataset_df = dataset_df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31854774143 31854774142 31854774141 3185477414...</td>\n",
       "      <td>23732197760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42318532591 42318532590 42318532589 4231853258...</td>\n",
       "      <td>7432544128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48286355135 48286355134 48286355133 4828635513...</td>\n",
       "      <td>65249514352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>23732197823 23732197822 23732197821 2373219782...</td>\n",
       "      <td>58858693312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7432544179 7432544180 7432544178 7432544177 74...</td>\n",
       "      <td>5016497408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>42318532575 31854774141 31854774140 3185477413...</td>\n",
       "      <td>23732197809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>42318532585 42318532575 31854774141 3185477414...</td>\n",
       "      <td>23732197811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>23732197807 60916115883 23732197790 4231853258...</td>\n",
       "      <td>7432544134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>23732197809 23732197807 60916115883 2373219779...</td>\n",
       "      <td>7432544178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>23732197813 23732197811 23732197809 2373219780...</td>\n",
       "      <td>58858693333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     pa        label\n",
       "2     31854774143 31854774142 31854774141 3185477414...  23732197760\n",
       "3     42318532591 42318532590 42318532589 4231853258...   7432544128\n",
       "4     48286355135 48286355134 48286355133 4828635513...  65249514352\n",
       "5     23732197823 23732197822 23732197821 2373219782...  58858693312\n",
       "6     7432544179 7432544180 7432544178 7432544177 74...   5016497408\n",
       "...                                                 ...          ...\n",
       "9994  42318532575 31854774141 31854774140 3185477413...  23732197809\n",
       "9995  42318532585 42318532575 31854774141 3185477414...  23732197811\n",
       "9996  23732197807 60916115883 23732197790 4231853258...   7432544134\n",
       "9997  23732197809 23732197807 60916115883 2373219779...   7432544178\n",
       "9998  23732197813 23732197811 23732197809 2373219780...  58858693333\n",
       "\n",
       "[9997 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = dataset_df.iloc[:1600000]\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['label'] = dataset_df['label'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pa</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31854774143 31854774142 31854774141 3185477414...</td>\n",
       "      <td>23732197760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42318532591 42318532590 42318532589 4231853258...</td>\n",
       "      <td>7432544128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48286355135 48286355134 48286355133 4828635513...</td>\n",
       "      <td>65249514352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23732197823 23732197822 23732197821 2373219782...</td>\n",
       "      <td>58858693312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7432544179 7432544180 7432544178 7432544177 74...</td>\n",
       "      <td>5016497408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>42318532575 31854774141 31854774140 3185477413...</td>\n",
       "      <td>23732197809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>42318532585 42318532575 31854774141 3185477414...</td>\n",
       "      <td>23732197811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>23732197807 60916115883 23732197790 4231853258...</td>\n",
       "      <td>7432544134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>23732197809 23732197807 60916115883 2373219779...</td>\n",
       "      <td>7432544178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>23732197813 23732197811 23732197809 2373219780...</td>\n",
       "      <td>58858693333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9997 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     pa        label\n",
       "0     31854774143 31854774142 31854774141 3185477414...  23732197760\n",
       "1     42318532591 42318532590 42318532589 4231853258...   7432544128\n",
       "2     48286355135 48286355134 48286355133 4828635513...  65249514352\n",
       "3     23732197823 23732197822 23732197821 2373219782...  58858693312\n",
       "4     7432544179 7432544180 7432544178 7432544177 74...   5016497408\n",
       "...                                                 ...          ...\n",
       "9992  42318532575 31854774141 31854774140 3185477413...  23732197809\n",
       "9993  42318532585 42318532575 31854774141 3185477414...  23732197811\n",
       "9994  23732197807 60916115883 23732197790 4231853258...   7432544134\n",
       "9995  23732197809 23732197807 60916115883 2373219779...   7432544178\n",
       "9996  23732197813 23732197811 23732197809 2373219780...  58858693333\n",
       "\n",
       "[9997 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df = dataset_df.reset_index(drop=True)\n",
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datatset / DataLoader / Vectorizer / Vocabulary / Model의 흐름에 대한 구성\n",
    "순서 : Vocabulary -> Vectorizer -> Dataset -> DataLoader -> Model\n",
    "\n",
    "Raw Data\n",
    "- 현 시점 cache에 존재하는 주소 목록 \n",
    "- ex: 125, 158, 154, 134, 145, 341, 133, 136\n",
    "- 주소를 숫자가 아닌 문자열로 보아야 함 (physical addr는 숫자의 의미보다 문자열의 의미가 더 강하다고 판단)\n",
    "- 주소를 하나의 토큰으로\n",
    "\n",
    "Vocabulary \n",
    "- 각 주소(토큰)를 정수로 매핑\n",
    "- 입력 및 출력의 대상이 되는 주소만을 가짐 (+-10정도 커버?)\n",
    "\n",
    "** Vectorizer ** \n",
    "- 매핑된 토큰을 벡터 형태로 변환\n",
    "\n",
    "Dataset \n",
    "- vectorizer 이용하여 구성\n",
    "\n",
    "DataLoader\n",
    "- 미니배치 단위로 데이터셋 가져옴\n",
    "\n",
    "Model\n",
    "- 초기값: 첫 주소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAVocabulary(object):\n",
    "    def __init__(self, token_to_idx = None, add_unk = True,\n",
    "                 mask_token = \"<MASK>\", unk_token = \"<UNK>\"):\n",
    "        if token_to_idx is None:\n",
    "            token_to_idx = {}\n",
    "        self._token_to_idx = token_to_idx\n",
    "        self._idx_to_token = {idx:token for token, idx in self._token_to_idx.items()}\n",
    "        \n",
    "        self._add_unk = add_unk\n",
    "        self._mask_token = mask_token\n",
    "        self._unk_token = unk_token\n",
    "        \n",
    "        self.mask_index = self.add_token(self._mask_token)\n",
    "        self.unk_index = -1\n",
    "        if add_unk:\n",
    "            self.unk_index = self.add_token(self._unk_token)\n",
    "\n",
    "    def to_serializable(self):\n",
    "        return {'token_to_idx': self._token_to_idx, \n",
    "                'add_unk': self._add_unk, \n",
    "                'unk_token': self._unk_token}\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, cstates):\n",
    "        return cls(**cstates)\n",
    "    \n",
    "    def add_token(self, token):\n",
    "        if token in self._token_to_idx:\n",
    "            index = self._token_to_idx[token]\n",
    "        else:\n",
    "            index = len(self._token_to_idx)\n",
    "            self._token_to_idx[token] = index\n",
    "            self._idx_to_token[index] = token\n",
    "        return index\n",
    "    \n",
    "    def lookup_token(self, token):\n",
    "        if self.unk_index >= 0:\n",
    "            return self._token_to_idx.get(token, self.unk_index)\n",
    "        else:\n",
    "            return self._token_to_idx[token]\n",
    "        \n",
    "    def lookup_index(self, index):\n",
    "        if index not in self._idx_to_token:\n",
    "            raise KeyError(\"the index (%d) is not in the Vocabulary\" %index)\n",
    "        return self._idx_to_token[index]\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"<Vocabulary(size=%d)>\"%len(self)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._token_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizer\n",
    "- max_len에 대한 조건 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PAVectorizer(object):\n",
    "    def __init__(self, pa_vocab):\n",
    "        self.pa_vocab = pa_vocab\n",
    "        # self.max_la_length = max_pa_length\n",
    "    \n",
    "    def _vectorize(self, indices):\n",
    "        vector_length = len(indices)\n",
    "        vector = np.zeros(vector_length, dtype=np.int64)\n",
    "        vector[:len(indices)] = indices\n",
    "        return vector\n",
    "        \n",
    "    def _get_pa_indices(self, pa_list):\n",
    "        # print(pa_list)\n",
    "        # print(type(pa_list))\n",
    "        # 벡터로 변환된 physical addr list 반환\n",
    "        indices = [self.pa_vocab.lookup_token(token) for token in pa_list.split(\" \")]\n",
    "        return indices\n",
    "    \n",
    "    def vectorize(self, cstate):\n",
    "        pa_indices = self._get_pa_indices(cstate)\n",
    "        pa_vector = self._vectorize(indices=pa_indices)\n",
    "        return {'pa_vector':pa_vector,\n",
    "                'pa_length':len(pa_indices)}\n",
    "        \n",
    "    @classmethod\n",
    "    def from_dataframe(cls, cstate_df):\n",
    "        pa_vocab = PAVocabulary()\n",
    "        pa_counts = Counter()\n",
    "        for cstate in cstate_df.pa:\n",
    "            for pa in cstate.split(\" \"):\n",
    "                pa_counts[pa] += 1\n",
    "        for cstate in cstate_df.label:\n",
    "            pa_counts[cstate] += 1\n",
    "        \n",
    "        for pa, count in pa_counts.items():\n",
    "            if count >= args.cut_off:\n",
    "                pa_vocab.add_token(pa)\n",
    "        print(\"vectorizer vocab len: \",len(pa_vocab))\n",
    "        return cls(pa_vocab)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_serializable(cls, cstate_dict):\n",
    "        pa_vocab = PAVocabulary.from_serializable(cstate_dict['pa_vocab'])\n",
    "        return cls(pa_vocab)\n",
    "    \n",
    "    def to_serializable(self):\n",
    "        return {'pa_vocab': self.pa_vocab.to_serializable()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CstateDataset(Dataset):\n",
    "    def __init__(self, cstate_df, vectorizer):\n",
    "        self.cstate_df = cstate_df\n",
    "        self._vectorizer = vectorizer\n",
    "        \n",
    "        self.n_total = len(cstate_df)\n",
    "        \n",
    "        self.train_size = int(self.n_total * args.perc_train)\n",
    "        self.train_df = self.cstate_df.loc[:self.train_size]\n",
    "        \n",
    "        self.val_size = int(self.n_total * args.perc_val)\n",
    "        self.val_df = self.cstate_df.loc[self.train_size : self.train_size+self.val_size]\n",
    "        \n",
    "        self.test_size = self.n_total - (self.train_size + self.val_size)\n",
    "        self.test_df = self.cstate_df.loc[self.train_size+self.val_size:]\n",
    "        \n",
    "        self.vocab_df_size = self.n_total\n",
    "        self.vocab_df = self.cstate_df\n",
    "        \n",
    "        self._lookup_dict = {'train': (self.train_df, self.train_size),\n",
    "                             'val': (self.val_df, self.val_size),\n",
    "                             'test': (self.test_df, self.test_size),\n",
    "                             'vocab': (self.vocab_df, self.vocab_df_size)}\n",
    "        \n",
    "        self.set_split('vocab')\n",
    "        \n",
    "    @classmethod\n",
    "    def load_dataset_and_make_vectorizer(cls, cstate_df):\n",
    "        # cstate_df = pd.read_csv(cstate_csv)\n",
    "        vocab_cstate_df = cstate_df.loc[:int(len(cstate_df)*args.perc_vocab)]\n",
    "        print(\"dataset df len:\", len(vocab_cstate_df))\n",
    "        vectorizer = PAVectorizer.from_dataframe(vocab_cstate_df)\n",
    "        \n",
    "        return cls(cstate_df, vectorizer)\n",
    "\n",
    "    @classmethod\n",
    "    def load_dataset_and_load_vectorizer(cls, cstate_df, vectorizer_filepath):\n",
    "        vocab_cstate_df = cstate_df\n",
    "        vectorizer = cls.load_vectorizer_only(vectorizer_filepath)\n",
    "        return cls(vocab_cstate_df, vectorizer)\n",
    "    \n",
    "    @classmethod\n",
    "    def load_vectorizer_only(vectorizer_filepath):\n",
    "        with open(vectorizer_filepath) as fp:\n",
    "            return PAVectorizer.from_serializable(json.load(fp))\n",
    "        \n",
    "    def save_vectorizer(self, vectorizer_filepath):\n",
    "        with open(vectorizer_filepath, \"w\") as fp:\n",
    "            json.dump(self._vectorizer.to_serializable(), fp)\n",
    "            \n",
    "    def get_vectorizer(self):\n",
    "        return self._vectorizer\n",
    "    \n",
    "    def set_split(self, split='train'):\n",
    "        self._target_split = split\n",
    "        self._target_df, self._target_size = self._lookup_dict[split]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self._target_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self._target_df.iloc[index]\n",
    "        pa_vector = self._vectorizer.vectorize(row.pa)\n",
    "        label_vector = self._vectorizer.vectorize(row.label)\n",
    "        \n",
    "        return {'x_data': pa_vector['pa_vector'],\n",
    "                'y_target': label_vector['pa_vector'],\n",
    "                'x_data_length': pa_vector['pa_length']}\n",
    "        \n",
    "    def get_num_batches(self, batch_size):\n",
    "        return len(self) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(dataset, batch_size, shuffle=False, drop_last=True, device='cpu'):\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict={}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.attn_fc = nn.Linear(in_features=hidden_size, out_features=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.attn_fc(x)\n",
    "        # print(x.shape)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prefetcher(nn.Module):\n",
    "    def __init__(self, args, vocab_size):\n",
    "        super(Prefetcher, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                      embedding_dim=args.embedding_size)\n",
    "        self.lstm = nn.LSTM(input_size = args.embedding_size,\n",
    "                            hidden_size=args.encoding_size,\n",
    "                            num_layers=2,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True,\n",
    "                            dropout=0.1)\n",
    "        self.attention = Attention(args.encoding_size*2)\n",
    "        self.fc2 = nn.Linear(in_features=args.max_len, out_features=vocab_size)\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.embedding(x)\n",
    "        # print(x.shape)\n",
    "        output, hidden = self.lstm(x)\n",
    "        # print(output.shape)\n",
    "        attn_weights = self.attention(output)\n",
    "        # print(attn_weights.shape)\n",
    "        attn_output = output * attn_weights\n",
    "        # print(attn_output.shape)\n",
    "        attn_output = torch.sum(attn_output, dim=-1)\n",
    "        # print(attn_output.shape)\n",
    "        x = self.fc2(attn_output)\n",
    "        # print(x.shape)\n",
    "        x = self.softmax(x)\n",
    "        # print(x.shape)\n",
    "        x = x.squeeze()\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "dataset df len: 9997\n",
      "vectorizer vocab len:  1056\n"
     ]
    }
   ],
   "source": [
    "# 현재 사용가능한 디바이스로 환경변수 device 재설정\n",
    "args.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(args.device)\n",
    "# 학습에 사용할 데이터셋 파일 가져와서 Dataset 객체 만들기 \n",
    "dataset = CstateDataset.load_dataset_and_make_vectorizer(dataset_df)\n",
    "# dataset 객체를 만들면 안에서 vectorizer 객체도 생성되기 때문에 여기서 vectorizer 뽑아낼 수 있음\n",
    "vectorizer = dataset.get_vectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Prefetcher(args, len(vectorizer.pa_vocab)).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1056"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.pa_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "# 학습률을 매 스텝마다 0.5배로 조정\n",
    "# 아래 학습의 경우, 에폭마다 0.5배하도록 했음 -> 적은데이터 수로 인해 학습속도가 매우 빨라서 매 에폭마다 조절 필요하다고 판단함\n",
    "# 어차피 매 에폭마다 학습률 줄이는 방향으로 조절할 것이기 때문에 가장 단순한 StepLR 통해 학습률을 조정하고자 했음\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode='min', factor=0.5, patience=1)\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.NLLLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (X / X Steps) (loss=X.X): 0it [00:00, ?it/s]/tmp/ipykernel_130219/2672553311.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n",
      "Training (77 / 78 Steps) (loss=6.96350): : 78it [00:04, 16.28it/s]\n",
      "Validation (30 / 78 Steps) (loss=6.94973): : 31it [00:00, 31.65it/s]\n",
      "Training (77 / 78 Steps) (loss=6.87260): : 78it [00:04, 15.97it/s]\n",
      "Validation (30 / 78 Steps) (loss=7.01424): : 31it [00:00, 31.84it/s]\n",
      "Training (77 / 78 Steps) (loss=6.78477): : 78it [00:04, 16.36it/s]\n",
      "Validation (30 / 78 Steps) (loss=7.04560): : 31it [00:00, 31.95it/s]\n",
      "Training (77 / 78 Steps) (loss=6.63523): : 78it [00:04, 16.52it/s]\n",
      "Validation (30 / 78 Steps) (loss=7.11801): : 31it [00:00, 31.66it/s]\n",
      "Training (77 / 78 Steps) (loss=6.35725): : 78it [00:04, 16.09it/s]\n",
      "Validation (30 / 78 Steps) (loss=7.25335): : 31it [00:00, 31.39it/s]\n",
      "Training (77 / 78 Steps) (loss=6.21827): : 78it [00:04, 16.51it/s]\n",
      "Validation (30 / 78 Steps) (loss=7.36972): : 31it [00:00, 31.54it/s]\n",
      "Training (77 / 78 Steps) (loss=6.08187): : 78it [00:04, 16.12it/s]\n",
      "Validation (30 / 78 Steps) (loss=7.45084): : 31it [00:00, 31.27it/s]\n",
      "Training (77 / 78 Steps) (loss=6.02936): : 78it [00:04, 15.91it/s]\n",
      "Validation (5 / 78 Steps) (loss=7.38678): : 6it [00:00, 27.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, batch_dict \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(val_iterator):\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 61\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx_data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         loss \u001b[38;5;241m=\u001b[39m criterion(output, batch_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mto(args\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m     63\u001b[0m         epoch_val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/prefetch/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m, in \u001b[0;36mPrefetcher.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(x)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(x.shape)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# print(output.shape)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattention(output)\n",
      "File \u001b[0;32m~/miniconda3/envs/prefetch/lib/python3.9/site-packages/torch/nn/modules/module.py:727\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    726\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 727\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    729\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    731\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/miniconda3/envs/prefetch/lib/python3.9/site-packages/torch/nn/modules/rnn.py:581\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    584\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    585\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습 중 학습데이터 및 검증데이터에 대한 손실값을 출력하기 위한 변수\n",
    "epoch_train_loss = 0.0\n",
    "epoch_val_loss = 0.0\n",
    "# 학습 중 손실값 혹은 metric 적용에 대한 결과값 등을 기록해두기 위한 리스트\n",
    "logs=[]\n",
    "# 학습을 시작할 epoch 지정\n",
    "start_epoch = 0\n",
    "weight_file = f'models/model_{start_epoch}.pth'\n",
    "# pretrained model load\n",
    "if start_epoch!=0:\n",
    "    pre_weights = torch.load(weight_file, map_location=args.device)\n",
    "    model.load_state_dict(pre_weights)\n",
    "    \n",
    "for epoch in range(start_epoch, args.num_epoch):\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_val_loss = 0.0\n",
    "    # train_log_df = pd.DataFrame()\n",
    "    dataset.set_split('train')\n",
    "    train_batch_generator = generate_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "    total = dataset.get_num_batches(args.batch_size)\n",
    "    train_iterator = tqdm(train_batch_generator, desc=\"Training (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "    # for batch_idx, batch_dict in enumerate(train_batch_generator):\n",
    "    for batch_idx, batch_dict in enumerate(train_iterator):\n",
    "        # if batch_idx >= 24990:\n",
    "        #     print(batch_idx, \":\", batch_dict['x_data'].shape)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_dict['x_data'].to(args.device))\n",
    "        # 확률 분포로 변환 (소프트맥스 함수 사용)\n",
    "        # probabilities = F.softmax(y_pred, dim=1)\n",
    "        # loss = criterion(y_pred, batch_dict['y_target'].float().to(args.device))\n",
    "        # 타겟을 정수형으로 변환\n",
    "        # y_target = batch_dict['y_target'].to(torch.long).to(args.device)\n",
    "\n",
    "        # Negative Log Likelihood Loss를 사용하여 손실 계산\n",
    "        # loss = F.nll_loss(torch.log(probabilities), y_target)\n",
    "        # print(y_pred.shape)\n",
    "        # print(torch.argmax(y_pred, dim=1))\n",
    "        # print(y_pred)\n",
    "        # print(batch_dict['y_target'].shape)\n",
    "        # print(batch_dict['y_target'])\n",
    "        loss = criterion(y_pred, batch_dict['y_target'].squeeze().to(args.device))\n",
    "        epoch_train_loss += loss.item()\n",
    "        train_iterator.set_description(\"Training (%d / %d Steps) (loss=%2.5f)\" %(batch_idx, total, loss))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # epoch loss log\n",
    "    # output_train_df = pd.DataFrame({'epoch':epoch+1, 'loss':epoch_train_loss})\n",
    "    # train_log_df = pd.concat([train_log_df, output_train_df])\n",
    "    # train_log_df.to_csv(\"train_log.csv\")\n",
    "    # scheduler.step()\n",
    "\n",
    "    # validation\n",
    "    if(epoch+1) % 1 == 0:\n",
    "        # val_log_df = pd.DataFrame()\n",
    "        dataset.set_split('val')\n",
    "        val_batch_generator = generate_batches(dataset, batch_size=args.batch_size, device=args.device)\n",
    "        val_iterator = tqdm(val_batch_generator, desc=\"Validation (X / X Steps) (loss=X.X)\", dynamic_ncols=True)\n",
    "        for batch_idx, batch_dict in enumerate(val_iterator):\n",
    "            with torch.no_grad():\n",
    "                output = model(batch_dict['x_data'].to(args.device))\n",
    "                loss = criterion(output, batch_dict['y_target'].squeeze().to(args.device))\n",
    "                epoch_val_loss += loss.item()\n",
    "                val_iterator.set_description(\"Validation (%d / %d Steps) (loss=%2.5f)\" %(batch_idx, total, loss))\n",
    "        # output_val_df = pd.DataFrame({'epoch':epoch+1, 'loss':epoch_val_loss})\n",
    "        # val_log_df = pd.concat([val_log_df, output_val_df])\n",
    "        # val_log_df.to_csv(\"val_log.csv\")\n",
    "    scheduler.step(epoch_val_loss/dataset.get_num_batches(32))\n",
    "    # scheduler.step()\n",
    "    log_epoch = {'epoch':epoch+1, 'train_loss':epoch_train_loss, 'val_loss':epoch_val_loss}\n",
    "    logs.append(log_epoch)\n",
    "    log_df = pd.DataFrame(logs)\n",
    "    log_df.to_csv(\"log/log_output.csv\")\n",
    "    \n",
    "    # model save\n",
    "    if(epoch+1) % 5 == 0:\n",
    "        torch.save(model.state_dict(), 'models/model_'+str(epoch+1)+'.pth')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test (X / X Steps): 0it [00:00, ?it/s]/tmp/ipykernel_130219/2672553311.py:30: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.softmax(x)\n",
      "Test (0 / 3000 Steps): : 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test (2999 / 3000 Steps): : 3000it [00:37, 79.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n",
      "3.1\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('models/model_20.pth'))\n",
    "model = model.to(args.device)\n",
    "result_df = pd.DataFrame()\n",
    "dataset.set_split('test')\n",
    "test_batch_generator = generate_batches(dataset, batch_size=1, device=args.device)\n",
    "test_iterator = tqdm(test_batch_generator, desc=\"Test (X / X Steps)\", dynamic_ncols=True)\n",
    "test_total = dataset.get_num_batches(1)\n",
    "correct = 0\n",
    "with torch.no_grad():\n",
    "    # for _, data in enumerate(test_batch_generator):\n",
    "    for idx, data in enumerate(test_iterator):\n",
    "        output = model(data['x_data'].to(args.device))\n",
    "        topk_vals, topk_indices = torch.topk(output, 20)\n",
    "        toplist = topk_indices.detach().cpu().tolist()\n",
    "        target = data['y_target'].squeeze().cpu().detach().numpy()\n",
    "        output_df = pd.DataFrame({'pred':[toplist], 'target':target})\n",
    "        result_df = pd.concat([result_df, output_df])\n",
    "        if target in toplist:\n",
    "            correct+=1\n",
    "        test_iterator.set_description(\"Test (%d / %d Steps)\" %(idx, test_total))\n",
    "print(correct)\n",
    "print(correct/test_total*100)\n",
    "result_df.to_csv('test_results/test_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.2905, -3.5925, -3.7852, -3.7986, -3.8506, -3.8742, -4.0041, -4.0068,\n",
       "        -4.0105, -4.0223])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_vals.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6231, 6180, 6182, 6444, 6103, 5933, 6216, 6226, 6262, 6081],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_10 = 0\n",
    "for idx, row in result_df.iterrows():\n",
    "    if row.target in row.pred[:10]:\n",
    "        cor_10+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.130000000000003"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor_10 / len(result_df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prefetch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
